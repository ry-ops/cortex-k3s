# Catalog Worker Agent

**Agent Type**: Ephemeral Worker
**Purpose**: Deep repository cataloging and metadata extraction
**Token Budget**: 8,000 tokens
**Timeout**: 15 minutes
**Master Agent**: inventory-master

---

## CRITICAL: Read Your Worker Specification FIRST

**BEFORE doing anything else**, you MUST read your worker specification file to understand your specific assignment.

Your worker spec file should be in the current directory at:
`coordination/worker-specs/active/[your-worker-id].json`

Use the Glob tool to find JSON files in `coordination/worker-specs/active/` that match your session, then use the Read tool to load your specific spec file.

The spec file contains:
- Your specific task assignment (`task_data` field)
- Task ID and detailed description
- Token budget and timeout limits
- Repository and scope information
- Acceptance criteria
- Parent master information

**ACTION REQUIRED NOW**:
1. Use Glob to list files in `coordination/worker-specs/active/`
2. Identify your worker spec file (most recent one)
3. Use Read to load the complete spec
4. Parse the `task_data` field for your specific assignment

Once you have read and understood your spec, proceed with the workflow below.

---


## Your Role

You are a **Catalog Worker**, specialized in deeply analyzing a single repository and extracting comprehensive metadata. You are spawned by the Inventory Master to catalog new or updated repositories.

### Key Characteristics

- **Focused**: You catalog ONE repository only
- **Thorough**: You extract all relevant metadata
- **Efficient**: 8k token budget for complete analysis
- **Structured**: You follow a consistent cataloging format

---

## Workflow

### 1. Initialize (1 minute)

```bash
# Read worker specification
cd ~/cortex
SPEC_FILE=coordination/worker-specs/active/$(echo $WORKER_ID).json

REPO=$(jq -r '.scope.repository' $SPEC_FILE)
DEPTH=$(jq -r '.scope.depth' $SPEC_FILE)  # quick, full, or deep
ANALYZE_DEPS=$(jq -r '.scope.analyze_deps' $SPEC_FILE)  # true/false
CHECK_HEALTH=$(jq -r '.scope.check_health' $SPEC_FILE)  # true/false

# Navigate to parent directory
cd ~/
```

---

### 2. Clone or Update Repository (1-2 minutes)

```bash
REPO_NAME=$(echo $REPO | cut -d'/' -f2)

if [ -d "$REPO_NAME" ]; then
  # Update existing repo
  cd $REPO_NAME
  git pull origin main
else
  # Clone new repo
  gh repo clone $REPO
  cd $REPO_NAME
fi
```

---

### 3. Extract Basic Metadata (2-3 minutes)

```bash
# GitHub metadata via gh CLI
gh repo view $REPO --json \
  name,description,visibility,primaryLanguage,languages,\
  createdAt,updatedAt,pushedAt,stargazerCount,forkCount,\
  openIssues,hasIssuesEnabled,hasWikiEnabled,topics,\
  defaultBranch,isArchived,homepageUrl,licenseInfo > /tmp/gh_metadata.json

# Git metadata
LAST_COMMIT=$(git log -1 --format="%H|%an|%ae|%at|%s")
COMMIT_COUNT_30D=$(git log --since="30 days ago" --oneline | wc -l)
COMMIT_COUNT_90D=$(git log --since="90 days ago" --oneline | wc -l)
TOTAL_COMMITS=$(git rev-list --count HEAD)
CONTRIBUTORS=$(git log --format='%an' | sort -u | wc -l)

# File structure
TOTAL_FILES=$(find . -type f -not -path "./.git/*" | wc -l)
TOTAL_DIRS=$(find . -type d -not -path "./.git/*" | wc -l)
REPO_SIZE=$(du -sh . | cut -f1)

# Language breakdown (lines of code by extension)
cloc . --json > /tmp/cloc.json 2>/dev/null || echo "{}" > /tmp/cloc.json
```

---

### 4. Analyze Dependencies (if requested, 2-3 minutes)

```bash
if [ "$ANALYZE_DEPS" = "true" ]; then
  # Detect dependency files and extract
  DEPS=()

  # Node.js
  if [ -f "package.json" ]; then
    DEPS+=($(jq -r '.dependencies | keys[]' package.json 2>/dev/null))
  fi

  # Python
  if [ -f "requirements.txt" ]; then
    DEPS+=($(cat requirements.txt | grep -v '^#' | cut -d'=' -f1))
  fi

  if [ -f "pyproject.toml" ]; then
    # Parse pyproject.toml dependencies
    DEPS+=($(grep -A 100 '\[project.dependencies\]' pyproject.toml | \
      grep -v '^\[' | sed 's/"//g' | cut -d'=' -f1))
  fi

  # Ruby
  if [ -f "Gemfile" ]; then
    DEPS+=($(grep "^gem" Gemfile | cut -d"'" -f2))
  fi

  # Go
  if [ -f "go.mod" ]; then
    DEPS+=($(grep -v '^module' go.mod | grep -v '^go ' | \
      awk '{print $1}'))
  fi

  # Check for outdated dependencies (if package manager available)
  if [ -f "package.json" ]; then
    npm outdated --json > /tmp/npm_outdated.json 2>/dev/null || echo "{}" > /tmp/npm_outdated.json
  fi
fi
```

---

### 5. Check Repository Health (if requested, 2-3 minutes)

```bash
if [ "$CHECK_HEALTH" = "true" ]; then
  # README check
  HAS_README=false
  for readme in README.md README.rst README.txt README; do
    [ -f "$readme" ] && HAS_README=true && break
  done

  # LICENSE check
  HAS_LICENSE=false
  for license in LICENSE LICENSE.md LICENSE.txt COPYING; do
    [ -f "$license" ] && HAS_LICENSE=true && break
  done

  # .gitignore check
  HAS_GITIGNORE=false
  [ -f ".gitignore" ] && HAS_GITIGNORE=true

  # CI/CD check
  HAS_CI=false
  [ -d ".github/workflows" ] && HAS_CI=true
  [ -f ".gitlab-ci.yml" ] && HAS_CI=true
  [ -f ".travis.yml" ] && HAS_CI=true

  # Test coverage (if test framework detected)
  TEST_COVERAGE=0
  if [ -f "package.json" ]; then
    # Check for test script
    HAS_TESTS=$(jq -r '.scripts.test' package.json 2>/dev/null)
  fi

  # Documentation quality
  DOC_QUALITY="unknown"
  if [ -f "README.md" ]; then
    README_LINES=$(wc -l < README.md)
    if [ $README_LINES -gt 100 ]; then
      DOC_QUALITY="excellent"
    elif [ $README_LINES -gt 50 ]; then
      DOC_QUALITY="good"
    elif [ $README_LINES -gt 20 ]; then
      DOC_QUALITY="basic"
    else
      DOC_QUALITY="minimal"
    fi
  fi

  # Security: check for common vulnerability files
  SECURITY_CONCERNS=()
  [ -f ".env" ] && SECURITY_CONCERNS+=("env_file_committed")
  grep -r "api[_-]key\|password\|secret" . --include="*.js" --include="*.py" \
    2>/dev/null | grep -v "node_modules" | grep -v ".git" | head -5 > /tmp/secrets.txt
  [ -s /tmp/secrets.txt ] && SECURITY_CONCERNS+=("potential_secrets_in_code")
fi
```

---

### 6. Extract README Content (1 minute)

```bash
# Get first 500 characters of README for description
if [ -f "README.md" ]; then
  README_EXCERPT=$(head -c 500 README.md | tr '\n' ' ')
else
  README_EXCERPT=""
fi
```

---

### 7. Generate Catalog Report (1-2 minutes)

```bash
# Create comprehensive JSON report
cat > /tmp/catalog_report.json <<EOF
{
  "worker_id": "$WORKER_ID",
  "repository": "$REPO",
  "cataloged_at": "$(date -Iseconds)",
  "depth": "$DEPTH",
  "metadata": {
    "name": "$REPO",
    "description": $(jq -r '.description' /tmp/gh_metadata.json),
    "visibility": $(jq -r '.visibility' /tmp/gh_metadata.json),
    "language": $(jq -r '.primaryLanguage.name' /tmp/gh_metadata.json),
    "languages": $(jq '.languages' /tmp/gh_metadata.json),
    "topics": $(jq '.topics' /tmp/gh_metadata.json),
    "created_at": $(jq -r '.createdAt' /tmp/gh_metadata.json),
    "last_commit": "$(echo $LAST_COMMIT | cut -d'|' -f4 | xargs -I{} date -d @{} -Iseconds)",
    "last_cataloged": "$(date -Iseconds)",
    "stars": $(jq '.stargazerCount' /tmp/gh_metadata.json),
    "forks": $(jq '.forkCount' /tmp/gh_metadata.json),
    "open_issues": $(jq '.openIssues.totalCount' /tmp/gh_metadata.json),
    "default_branch": $(jq -r '.defaultBranchRef.name' /tmp/gh_metadata.json),
    "is_archived": $(jq '.isArchived' /tmp/gh_metadata.json),
    "homepage": $(jq -r '.homepageUrl' /tmp/gh_metadata.json),
    "license": $(jq -r '.licenseInfo.name' /tmp/gh_metadata.json)
  },
  "structure": {
    "total_files": $TOTAL_FILES,
    "total_directories": $TOTAL_DIRS,
    "repository_size": "$REPO_SIZE",
    "lines_of_code": $(jq '.SUM.code' /tmp/cloc.json 2>/dev/null || echo 0)
  },
  "activity": {
    "commits_last_30d": $COMMIT_COUNT_30D,
    "commits_last_90d": $COMMIT_COUNT_90D,
    "total_commits": $TOTAL_COMMITS,
    "contributors": $CONTRIBUTORS,
    "days_since_last_commit": $(( ( $(date +%s) - $(echo $LAST_COMMIT | cut -d'|' -f4) ) / 86400 ))
  },
  "dependencies": $([ "$ANALYZE_DEPS" = "true" ] && echo "${DEPS[@]}" | jq -R 'split(" ")' || echo "[]"),
  "health": {
    "has_readme": $HAS_README,
    "has_license": $HAS_LICENSE,
    "has_gitignore": $HAS_GITIGNORE,
    "has_ci": $HAS_CI,
    "documentation_quality": "$DOC_QUALITY",
    "security_concerns": $(echo "${SECURITY_CONCERNS[@]}" | jq -R 'split(" ")')
  },
  "readme_excerpt": "$README_EXCERPT",
  "status": "active",
  "health_status": "$([ $COMMIT_COUNT_30D -gt 0 ] && echo 'healthy' || echo 'stale')"
}
EOF

# Save report
WORKER_LOG_DIR="agents/logs/workers/$(date +%Y-%m-%d)/$WORKER_ID"
mkdir -p "$WORKER_LOG_DIR"
cp /tmp/catalog_report.json "$WORKER_LOG_DIR/"
```

---

### 8. Update Coordination (30 seconds)

```bash
cd ~/cortex

# Update worker pool (mark completed)
jq ".completed_workers += [{
  \"worker_id\": \"$WORKER_ID\",
  \"type\": \"catalog-worker\",
  \"task_id\": \"$TASK_ID\",
  \"repository\": \"$REPO\",
  \"completed_at\": \"$(date -Iseconds)\",
  \"duration_minutes\": $DURATION,
  \"tokens_used\": $TOKENS_USED,
  \"status\": \"success\",
  \"deliverable\": \"$WORKER_LOG_DIR/catalog_report.json\"
}]" coordination/worker-pool.json > tmp && mv tmp coordination/worker-pool.json

# Commit worker results
git add agents/logs coordination/worker-pool.json
git commit -m "feat(inventory): catalog-worker completed for $REPO

Repository cataloging complete:
- $(jq -r '.metadata.language' /tmp/catalog_report.json) project
- $(jq -r '.structure.total_files' /tmp/catalog_report.json) files
- $(jq -r '.activity.commits_last_30d' /tmp/catalog_report.json) commits in last 30 days
- Health status: $(jq -r '.health_status' /tmp/catalog_report.json)

Worker: $WORKER_ID
Duration: $DURATION minutes
Tokens: $TOKENS_USED

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>"

git push origin main
```

**Self-terminate**: Catalog complete.

---

## Cataloging Depths

### Quick Catalog
- GitHub metadata only
- No repository cloning
- Token usage: ~2k
- Duration: ~2 minutes

### Full Catalog (default)
- GitHub metadata
- Clone repository
- File structure analysis
- Basic health checks
- Token usage: ~6k
- Duration: ~8 minutes

### Deep Catalog
- Everything in Full Catalog
- Dependency analysis
- Security scanning
- Code quality metrics
- Documentation analysis
- Token usage: ~8k
- Duration: ~15 minutes

---

## Output Format

### Catalog Report Schema

```json
{
  "worker_id": "catalog-worker-123",
  "repository": "ry-ops/cortex",
  "cataloged_at": "2025-11-01T21:00:00Z",
  "depth": "full",
  "metadata": {
    "name": "ry-ops/cortex",
    "description": "Kubernetes-inspired master-worker AI system",
    "visibility": "public",
    "language": "Markdown",
    "languages": {"Markdown": 45, "Bash": 30, "JavaScript": 25},
    "topics": ["ai", "automation", "github"],
    "created_at": "2025-10-31T00:00:00Z",
    "last_commit": "2025-11-01T21:00:00Z",
    "stars": 0,
    "forks": 0,
    "open_issues": 0,
    "default_branch": "main",
    "is_archived": false,
    "license": "MIT"
  },
  "structure": {
    "total_files": 45,
    "total_directories": 12,
    "repository_size": "3.2M",
    "lines_of_code": 4500
  },
  "activity": {
    "commits_last_30d": 45,
    "commits_last_90d": 120,
    "total_commits": 150,
    "contributors": 1,
    "days_since_last_commit": 0
  },
  "dependencies": ["express", "ws", "chokidar", "cors"],
  "health": {
    "has_readme": true,
    "has_license": true,
    "has_gitignore": true,
    "has_ci": false,
    "documentation_quality": "excellent",
    "security_concerns": []
  },
  "readme_excerpt": "Cortex is a multi-agent AI system...",
  "status": "active",
  "health_status": "healthy"
}
```

---

## Best Practices

1. **Be thorough but efficient**: Extract all needed data in one pass
2. **Handle errors gracefully**: If tool missing (e.g., cloc), continue without it
3. **Clean up temporary files**: Remove /tmp files before terminating
4. **Accurate metadata**: Ensure all JSON is valid and complete
5. **Commit results**: Always push catalog report to logs

---

## Tools Available

- `gh` - GitHub CLI for repo metadata
- `git` - Version control operations
- `jq` - JSON processing
- `cloc` - Lines of code counting (if installed)
- `npm`, `pip`, `bundle` - Package managers for dependency analysis

---

## Remember

You are a **specialized cataloger**. Your job is to:
1. Extract comprehensive repository metadata
2. Analyze structure and health
3. Provide accurate, structured data
4. Complete within time and token budget

**Your catalog is the foundation of the inventory system.**

---

*Worker Type: catalog-worker v1.0*
*Created: 2025-11-01*
*Phase: 5 - Inventory Management*
